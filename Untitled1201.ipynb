{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af501e41-7ea0-40d7-8c96-4013a58a1ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded as CSV enc='utf-8', sep=',', shape=(6123270, 35)\n",
      "[OK] Built recommendation catalog: skills = 265  items = 53091  problem_col: problem_id\n",
      "\n",
      "[DONE] Recommender pack written to: C:\\Users\\sagni\\Downloads\\SkillTracer Knowledge Tracing\n",
      "  - reco_catalog.pkl, reco_catalog_preview.json\n",
      "  - recommender.py (no f-strings)\n",
      "  - app2.py\n",
      "  - index.html\n",
      "\n",
      "Start the API:\n",
      "  cd \"C:\\Users\\sagni\\Downloads\\SkillTracer Knowledge Tracing\"\n",
      "  uvicorn app2:app --host 0.0.0.0 --port 8000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SkillTracer — Next-Item Recommender + API + HTML (f-string safe)\n",
    "#   - Builds reco_catalog.pkl\n",
    "#   - Writes recommender.py (NO f-strings), app2.py, index.html\n",
    "# ============================================================\n",
    "import os, csv, json, pickle, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BASE = r\"C:\\Users\\sagni\\Downloads\\SkillTracer Knowledge Tracing\"\n",
    "DATA_PATH = os.path.join(BASE, r\"archive (1)\\2012-2013-data-with-predictions-4-final.csv\")\n",
    "PP_PATH   = os.path.join(BASE, \"preprocessor.pkl\")\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def is_zip_or_xlsx(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return f.read(2) == b\"PK\"\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def robust_read_any(path, usecols=None):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    if is_zip_or_xlsx(path):\n",
    "        import openpyxl\n",
    "        df = pd.read_excel(path, engine=\"openpyxl\", usecols=usecols)\n",
    "        print(f\"[INFO] Loaded as Excel: {os.path.basename(path)} shape={df.shape}\")\n",
    "        return df\n",
    "    encodings = [\"utf-8\",\"utf-8-sig\",\"cp1252\",\"latin1\"]\n",
    "    delimiters = [\";\", \",\", \"\\t\", \"|\"]\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            head = f.read(8192).decode(\"latin1\", errors=\"ignore\")\n",
    "        try:\n",
    "            sniffed = csv.Sniffer().sniff(head)\n",
    "            if sniffed.delimiter in delimiters:\n",
    "                delimiters = [sniffed.delimiter] + [d for d in delimiters if d != sniffed.delimiter]\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception:\n",
    "        pass\n",
    "    last_err = None\n",
    "    for enc in encodings:\n",
    "        for sep in delimiters:\n",
    "            try:\n",
    "                df = pd.read_csv(path, encoding=enc, sep=sep, engine=\"python\", usecols=usecols)\n",
    "                if df.shape[1] > 1:\n",
    "                    print(f\"[INFO] Loaded as CSV enc='{enc}', sep='{sep}', shape={df.shape}\")\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                continue\n",
    "    raise RuntimeError(f\"Could not parse {path}. Last error: {last_err}\")\n",
    "\n",
    "def pick_col(candidates, cols):\n",
    "    for c in candidates:\n",
    "        if c in cols: return c\n",
    "    lc = {c.lower(): c for c in cols}\n",
    "    for c in candidates:\n",
    "        if c.lower() in lc: return lc[c.lower()]\n",
    "    return None\n",
    "\n",
    "# ---------- load preprocessor (skill mapping) ----------\n",
    "if not os.path.exists(PP_PATH):\n",
    "    raise FileNotFoundError(\"preprocessor.pkl not found. Train first to create it.\")\n",
    "with open(PP_PATH, \"rb\") as f:\n",
    "    preproc = pickle.load(f)\n",
    "skill2idx = preproc[\"skill2idx\"]\n",
    "idx2skill = preproc.get(\"idx2skill\", {i:s for s,i in skill2idx.items()})\n",
    "n_skills  = preproc[\"n_skills\"]\n",
    "\n",
    "# ---------- load dataset and pick needed columns ----------\n",
    "df_all = robust_read_any(DATA_PATH)\n",
    "cols = list(df_all.columns)\n",
    "\n",
    "student_col = pick_col([\"student_id\",\"user_id\",\"Anon Student Id\",\"Anon StudentID\",\"student\",\"sid\"], cols)\n",
    "skill_col   = pick_col([\"skill_id\",\"skill\",\"tag\",\"KC(SubSkills)\",\"KC\",\"skill_name\",\"concept_id\"], cols)\n",
    "problem_col = pick_col([\"problem_id\",\"item_id\",\"problem\",\"question_id\",\"Step ID\",\"Problem Name\"], cols)\n",
    "correct_col = pick_col([\"correct\",\"is_correct\",\"Correct First Attempt\",\"answered_correctly\",\"label\"], cols)\n",
    "\n",
    "need = [c for c in [student_col, skill_col, problem_col, correct_col] if c is not None]\n",
    "df = df_all[need].copy()\n",
    "del df_all\n",
    "\n",
    "if student_col is None or skill_col is None or correct_col is None:\n",
    "    raise ValueError(f\"Missing essential columns in dataset. Found: {cols}\")\n",
    "\n",
    "# Normalize\n",
    "df[correct_col] = pd.to_numeric(df[correct_col], errors=\"coerce\")\n",
    "df[correct_col] = (df[correct_col] > 0).astype(int)\n",
    "\n",
    "def take_first_skill(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v)\n",
    "    for sep in [\"~~\",\"; \", \";\", \",\", \"|\"]:\n",
    "        if sep in s: return s.split(sep)[0]\n",
    "    return s\n",
    "\n",
    "df[skill_col] = df[skill_col].apply(take_first_skill)\n",
    "df = df.dropna(subset=[skill_col, correct_col])\n",
    "\n",
    "# Filter to known skills (from training mapping)\n",
    "df = df[df[skill_col].astype(str).isin(skill2idx.keys())].copy()\n",
    "\n",
    "# ---------- compute per-skill stats ----------\n",
    "k = 1.0  # Laplace smoothing\n",
    "skill_grp = df.groupby(skill_col)[correct_col].agg(['sum','count']).rename(columns={'sum':'pos','count':'n'}).reset_index()\n",
    "skill_grp['p_correct'] = (skill_grp['pos'] + k) / (skill_grp['n'] + 2*k)\n",
    "\n",
    "# ---------- per-problem stats ----------\n",
    "item_stats = {}\n",
    "skill_to_items = {}\n",
    "if problem_col is not None:\n",
    "    need2 = df[[skill_col, problem_col, correct_col]].dropna()\n",
    "    item_grp = need2.groupby([skill_col, problem_col])[correct_col].agg(['sum','count']).rename(columns={'sum':'pos','count':'n'}).reset_index()\n",
    "    item_grp['p_correct'] = (item_grp['pos'] + k) / (item_grp['n'] + 2*k)\n",
    "    eps = 1e-6\n",
    "    item_grp['p_clip'] = item_grp['p_correct'].clip(eps, 1-eps)\n",
    "    item_grp['b'] = -np.log(item_grp['p_clip']/(1-item_grp['p_clip']))  # 1PL difficulty\n",
    "    for _, r in item_grp.iterrows():\n",
    "        sk = str(r[skill_col]); it = str(r[problem_col])\n",
    "        item_stats[it] = {\n",
    "            \"skill\": sk,\n",
    "            \"n\": int(r['n']),\n",
    "            \"p_correct\": float(r['p_correct']),\n",
    "            \"b\": float(r['b'])\n",
    "        }\n",
    "        skill_to_items.setdefault(sk, []).append(it)\n",
    "\n",
    "# ---------- skill stats dict ----------\n",
    "skill_stats = {}\n",
    "for _, r in skill_grp.iterrows():\n",
    "    sk = str(r[skill_col])\n",
    "    skill_stats[sk] = {\"n\": int(r['n']), \"p_correct\": float(r['p_correct'])}\n",
    "\n",
    "# ---------- save reco_catalog ----------\n",
    "reco_catalog = {\n",
    "    \"skill_stats\": skill_stats,\n",
    "    \"item_stats\": item_stats,\n",
    "    \"skill_to_items\": skill_to_items,\n",
    "    \"meta\": {\n",
    "        \"problem_col_found\": problem_col is not None,\n",
    "        \"problem_col_name\": problem_col,\n",
    "        \"smoothing_k\": k,\n",
    "        \"note\": \"1PL-style: P(correct) ~ sigmoid(theta_student - b_item); b estimated from global p_item.\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(BASE, \"reco_catalog.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(reco_catalog, f)\n",
    "with open(os.path.join(BASE, \"reco_catalog_preview.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"meta\": reco_catalog[\"meta\"], \"num_skills\": len(skill_stats), \"num_items\": len(item_stats)}, f, indent=2)\n",
    "\n",
    "print(\"[OK] Built recommendation catalog: skills =\", len(skill_stats), \" items =\", len(item_stats), \" problem_col:\", problem_col)\n",
    "\n",
    "# ---------- recommender.py (NO f-strings; use placeholder replacement) ----------\n",
    "recommender_py = textwrap.dedent('''\n",
    "import os, json, pickle, math, numpy as np\n",
    "\n",
    "BASE = r\"<<<BASE>>>\"\n",
    "PP_PATH   = os.path.join(BASE, \"preprocessor.pkl\")\n",
    "CATALOG   = os.path.join(BASE, \"reco_catalog.pkl\")\n",
    "THRESHOLD = os.path.join(BASE, \"threshold.json\")\n",
    "\n",
    "_pre = None\n",
    "_cat = None\n",
    "_thr = None\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1.0/(1.0+math.exp(-x))\n",
    "\n",
    "def _logit(p, eps=1e-6):\n",
    "    p = min(max(p, eps), 1-eps)\n",
    "    return math.log(p/(1-p))\n",
    "\n",
    "def _load_pre():\n",
    "    global _pre\n",
    "    if _pre is None:\n",
    "        with open(PP_PATH, \"rb\") as f:\n",
    "            _pre = pickle.load(f)\n",
    "    return _pre\n",
    "\n",
    "def _load_cat():\n",
    "    global _cat\n",
    "    if _cat is None:\n",
    "        with open(CATALOG, \"rb\") as f:\n",
    "            _cat = pickle.load(f)\n",
    "    return _cat\n",
    "\n",
    "def _load_thr(default=0.5):\n",
    "    global _thr\n",
    "    if _thr is None:\n",
    "        try:\n",
    "            with open(THRESHOLD, \"r\", encoding=\"utf-8\") as f:\n",
    "                _thr = float(json.load(f).get(\"best_threshold\", default))\n",
    "        except Exception:\n",
    "            _thr = default\n",
    "    return _thr\n",
    "\n",
    "def mastery_from_history(history, decay=0.3):\n",
    "    \"\"\"\n",
    "    Exponential moving average per-skill:\n",
    "    m_new = (1-decay)*m_prev + decay*correct\n",
    "    Returns dict: skill -> mastery in [0,1], plus global p_student.\n",
    "    \"\"\"\n",
    "    skill_m = {}\n",
    "    skill_w = {}\n",
    "    total_c = 0\n",
    "    for e in history:\n",
    "        if isinstance(e, dict):\n",
    "            sk, cr = str(e.get(\"skill\")), int(e.get(\"correct\", 0))\n",
    "        else:\n",
    "            sk, cr = str(e[0]), int(e[1])\n",
    "        if not sk:\n",
    "            continue\n",
    "        prev = skill_m.get(sk, 0.5)  # neutral start\n",
    "        skill_m[sk] = (1.0 - decay)*prev + decay*cr\n",
    "        skill_w[sk] = skill_w.get(sk, 0) + 1\n",
    "        total_c += cr\n",
    "    n = sum(skill_w.values())\n",
    "    p_student = (total_c + 1) / (n + 2) if n > 0 else 0.5  # Laplace\n",
    "    return skill_m, p_student\n",
    "\n",
    "def recommend(history, top_k=5, target_low=0.60, target_high=0.75, min_item_count=30):\n",
    "    \"\"\"\n",
    "    Returns top_k recommended problems (if available) or skills, aiming for predicted success in [target_low, target_high].\n",
    "    Uses a simple 1PL-IRT estimate: for each skill, theta_skill=logit(p_student_skill) via EMA; for each item, P=σ(theta - b_item).\n",
    "    Falls back to skill-level if no problem column in catalog.\n",
    "    \"\"\"\n",
    "    pre = _load_pre()\n",
    "    cat = _load_cat()\n",
    "    skill_stats = cat[\"skill_stats\"]\n",
    "    item_stats  = cat[\"item_stats\"]\n",
    "    skill_to_items = cat[\"skill_to_items\"]\n",
    "    has_items = cat[\"meta\"].get(\"problem_col_found\", False)\n",
    "\n",
    "    # per-skill mastery from history (EMA)\n",
    "    skill_m, _ = mastery_from_history(history, decay=0.3)\n",
    "\n",
    "    recs = []\n",
    "    if has_items and len(item_stats) > 0:\n",
    "        # item-level\n",
    "        for sk, mastery in skill_m.items():\n",
    "            base_p = skill_stats.get(sk, {}).get(\"p_correct\", 0.5)\n",
    "            theta = _logit( (0.9*mastery + 0.1*base_p) )\n",
    "            for it in skill_to_items.get(sk, []):\n",
    "                st = item_stats[it]\n",
    "                if st[\"n\"] < min_item_count:\n",
    "                    continue\n",
    "                p_hat = _sigmoid(theta - st[\"b\"])\n",
    "                if target_low <= p_hat <= target_high:\n",
    "                    score = -abs((target_low+target_high)/2.0 - p_hat)\n",
    "                    recs.append({\"problem_id\": it, \"skill\": sk, \"pred_success\": float(p_hat),\n",
    "                                 \"seen\": int(st[\"n\"]), \"p_item\": float(st[\"p_correct\"]), \"difficulty_b\": float(st[\"b\"]),\n",
    "                                 \"score\": float(score)})\n",
    "        # widen if not enough\n",
    "        if len(recs) < top_k:\n",
    "            extra = []\n",
    "            band_low  = max(0.50, target_low - 0.10)\n",
    "            band_high = min(0.85, target_high + 0.10)\n",
    "            for sk, mastery in skill_m.items():\n",
    "                base_p = skill_stats.get(sk, {}).get(\"p_correct\", 0.5)\n",
    "                theta = _logit( (0.9*mastery + 0.1*base_p) )\n",
    "                for it in skill_to_items.get(sk, []):\n",
    "                    st = item_stats[it]\n",
    "                    if st[\"n\"] < min_item_count:\n",
    "                        continue\n",
    "                    p_hat = _sigmoid(theta - st[\"b\"])\n",
    "                    if band_low <= p_hat <= band_high:\n",
    "                        score = -abs((target_low+target_high)/2.0 - p_hat)\n",
    "                        extra.append({\"problem_id\": it, \"skill\": sk, \"pred_success\": float(p_hat),\n",
    "                                      \"seen\": int(st[\"n\"]), \"p_item\": float(st[\"p_correct\"]), \"difficulty_b\": float(st[\"b\"]),\n",
    "                                      \"score\": float(score)})\n",
    "            recs = (recs + extra)\n",
    "        recs.sort(key=lambda x: (x[\"score\"], -x[\"seen\"]), reverse=True)\n",
    "        return recs[:top_k]\n",
    "    else:\n",
    "        # skill-level only\n",
    "        for sk, mastery in skill_m.items():\n",
    "            gap = 0.65 - mastery\n",
    "            score = -abs(gap)\n",
    "            recs.append({\"skill\": sk, \"mastery\": float(mastery), \"score\": float(score)})\n",
    "        recs.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        return recs[:top_k]\n",
    "''').replace(\"<<<BASE>>>\", BASE)\n",
    "\n",
    "with open(os.path.join(BASE, \"recommender.py\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(recommender_py)\n",
    "\n",
    "# ---------- app2.py (no f-strings) ----------\n",
    "app2_py = textwrap.dedent('''\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List, Optional, Union\n",
    "from predictor import predict, model_info\n",
    "from recommender import recommend\n",
    "\n",
    "app = FastAPI(title=\"SkillTracer API (with Recommender)\", version=\"1.1.0\",\n",
    "              description=\"Predict next correctness AND recommend next items.\")\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class HistoryEvent(BaseModel):\n",
    "    skill: str = Field(..., description=\"Skill/concept\")\n",
    "    correct: int = Field(..., ge=0, le=1)\n",
    "\n",
    "class PredictRequest(BaseModel):\n",
    "    history: List[Union[HistoryEvent, conlist(Union[str, int], min_items=2, max_items=2)]]\n",
    "    threshold: Optional[float] = Field(None, ge=0.0, le=1.0)\n",
    "\n",
    "class PredictResponse(BaseModel):\n",
    "    probability: Optional[float]\n",
    "    threshold: float\n",
    "    predicted_class: int\n",
    "    note: Optional[str] = None\n",
    "\n",
    "class RecommendRequest(BaseModel):\n",
    "    history: List[Union[HistoryEvent, conlist(Union[str, int], min_items=2, max_items=2)]]\n",
    "    top_k: int = Field(5, ge=1, le=20)\n",
    "    target_low: float = Field(0.60, ge=0.0, le=1.0)\n",
    "    target_high: float = Field(0.75, ge=0.0, le=1.0)\n",
    "    min_item_count: int = Field(30, ge=1, description=\"Only consider items seen at least this many times in training\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\", \"model\": model_info()}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictResponse)\n",
    "def predict_route(body: PredictRequest):\n",
    "    try:\n",
    "        normalized = []\n",
    "        for e in body.history:\n",
    "            if isinstance(e, list) or isinstance(e, tuple):\n",
    "                normalized.append({\"skill\": str(e[0]), \"correct\": int(e[1])})\n",
    "            else:\n",
    "                normalized.append({\"skill\": e.skill, \"correct\": e.correct})\n",
    "        return predict(normalized, threshold=body.threshold)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "@app.post(\"/recommend\")\n",
    "def recommend_route(body: RecommendRequest):\n",
    "    try:\n",
    "        normalized = []\n",
    "        for e in body.history:\n",
    "            if isinstance(e, list) or isinstance(e, tuple):\n",
    "                normalized.append({\"skill\": str(e[0]), \"correct\": int(e[1])})\n",
    "            else:\n",
    "                normalized.append({\"skill\": e.skill, \"correct\": e.correct})\n",
    "        recs = recommend(normalized, top_k=body.top_k,\n",
    "                         target_low=body.target_low, target_high=body.target_high,\n",
    "                         min_item_count=body.min_item_count)\n",
    "        return {\"recommendations\": recs}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\n",
    "        \"hello\": \"SkillTracer API (with Recommender)\",\n",
    "        \"docs\": \"/docs\",\n",
    "        \"try_predict\": {\n",
    "            \"history\": [[\"Algebra\",1], [\"Algebra\",0], [\"Fractions\",1]],\n",
    "            \"threshold\": 0.5\n",
    "        },\n",
    "        \"try_recommend\": {\n",
    "            \"history\": [[\"Algebra\",1], [\"Algebra\",0], [\"Fractions\",1]],\n",
    "            \"top_k\": 5, \"target_low\": 0.60, \"target_high\": 0.75\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run: uvicorn app2:app --host 0.0.0.0 --port 8000\n",
    "''')\n",
    "with open(os.path.join(BASE, \"app2.py\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(app2_py)\n",
    "\n",
    "# ---------- index.html ----------\n",
    "index_html = textwrap.dedent(r'''\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\"/>\n",
    "  <title>SkillTracer Demo</title>\n",
    "  <style>\n",
    "    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 30px; max-width: 900px; }\n",
    "    textarea { width: 100%; height: 120px; }\n",
    "    .row { display: flex; gap: 12px; align-items: center; }\n",
    "    .row > * { flex: 1; }\n",
    "    pre { background: #111; color: #0f0; padding: 12px; border-radius: 8px; overflow:auto; }\n",
    "    button { padding: 10px 16px; border-radius: 8px; border: 1px solid #ddd; cursor: pointer; }\n",
    "    button:hover { background: #f4f4f4; }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>SkillTracer — Predict & Recommend</h1>\n",
    "  <p><b>History JSON</b> (list of {\"skill\": \"...\", \"correct\": 0/1})</p>\n",
    "  <textarea id=\"hist\">[\n",
    "  {\"skill\":\"Algebra\",\"correct\":1},\n",
    "  {\"skill\":\"Algebra\",\"correct\":0},\n",
    "  {\"skill\":\"Fractions\",\"correct\":1}\n",
    "]</textarea>\n",
    "  <div class=\"row\">\n",
    "    <div>\n",
    "      <label>Threshold</label>\n",
    "      <input id=\"thr\" type=\"number\" step=\"0.01\" min=\"0\" max=\"1\" value=\"0.5\" />\n",
    "    </div>\n",
    "    <div>\n",
    "      <label>Top K</label>\n",
    "      <input id=\"topk\" type=\"number\" min=\"1\" max=\"20\" value=\"5\" />\n",
    "    </div>\n",
    "    <div>\n",
    "      <label>Target Band</label>\n",
    "      <input id=\"low\" type=\"number\" step=\"0.01\" min=\"0\" max=\"1\" value=\"0.60\" />\n",
    "      <input id=\"high\" type=\"number\" step=\"0.01\" min=\"0\" max=\"1\" value=\"0.75\" />\n",
    "    </div>\n",
    "  </div>\n",
    "  <p>\n",
    "    <button onclick=\"doPredict()\">Predict</button>\n",
    "    <button onclick=\"doRecommend()\">Recommend</button>\n",
    "  </p>\n",
    "  <h3>Response</h3>\n",
    "  <pre id=\"out\"></pre>\n",
    "\n",
    "<script>\n",
    "async function doPredict() {\n",
    "  const body = {\n",
    "    history: JSON.parse(document.getElementById('hist').value),\n",
    "    threshold: parseFloat(document.getElementById('thr').value)\n",
    "  };\n",
    "  const res = await fetch('/predict', {\n",
    "    method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify(body)\n",
    "  });\n",
    "  document.getElementById('out').textContent = JSON.stringify(await res.json(), null, 2);\n",
    "}\n",
    "async function doRecommend() {\n",
    "  const body = {\n",
    "    history: JSON.parse(document.getElementById('hist').value),\n",
    "    top_k: parseInt(document.getElementById('topk').value),\n",
    "    target_low: parseFloat(document.getElementById('low').value),\n",
    "    target_high: parseFloat(document.getElementById('high').value)\n",
    "  };\n",
    "  const res = await fetch('/recommend', {\n",
    "    method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify(body)\n",
    "  });\n",
    "  document.getElementById('out').textContent = JSON.stringify(await res.json(), null, 2);\n",
    "}\n",
    "</script>\n",
    "</body>\n",
    "</html>\n",
    "''')\n",
    "with open(os.path.join(BASE, \"index.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(index_html)\n",
    "\n",
    "print(\"\\n[DONE] Recommender pack written to:\", BASE)\n",
    "print(\"  - reco_catalog.pkl, reco_catalog_preview.json\")\n",
    "print(\"  - recommender.py (no f-strings)\")\n",
    "print(\"  - app2.py\")\n",
    "print(\"  - index.html\")\n",
    "print(\"\\nStart the API:\")\n",
    "print(r'  cd \"C:\\Users\\sagni\\Downloads\\SkillTracer Knowledge Tracing\"')\n",
    "print(r'  uvicorn app2:app --host 0.0.0.0 --port 8000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62050d38-2018-4443-b137-1824f879ca95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
